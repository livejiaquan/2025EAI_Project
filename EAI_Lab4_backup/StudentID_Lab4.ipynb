{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 581181,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 433802,
          "modelId": 450656
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Distillation\n",
        "- The concept of **knowledge distillation** is to utilize class probabilities of a higher-capacity model (teacher) as soft targets of a smaller model (student)\n",
        "- The implement processes can be divided into several stages:\n",
        "  1. Finish the `ResNet()` classes\n",
        "  2. Train the teacher model (ResNet50) and the student model (ResNet18) from scratch, i.e. **without KD**\n",
        "  3. Define the `Distiller()` class and `loss_re()`, `loss_fe()` functions\n",
        "  4. Train the student model **with KD** from the teacher model in two different ways, response-based and feature based distillation\n",
        "  5. Comparison of student models w/ & w/o KD"
      ],
      "metadata": {
        "id": "jgVOunpmwdT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "w40lLxA3wdT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torchinfo"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:20:41.614011Z",
          "iopub.execute_input": "2025-09-15T17:20:41.614280Z",
          "iopub.status.idle": "2025-09-15T17:20:46.740522Z",
          "shell.execute_reply.started": "2025-09-15T17:20:41.614239Z",
          "shell.execute_reply": "2025-09-15T17:20:46.739828Z"
        },
        "id": "xAYyvlYlwdT8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:20:46.742139Z",
          "iopub.execute_input": "2025-09-15T17:20:46.742442Z",
          "iopub.status.idle": "2025-09-15T17:20:56.618435Z",
          "shell.execute_reply.started": "2025-09-15T17:20:46.742411Z",
          "shell.execute_reply": "2025-09-15T17:20:56.617889Z"
        },
        "id": "NivvmktxwdT9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:20:56.619135Z",
          "iopub.execute_input": "2025-09-15T17:20:56.619518Z",
          "iopub.status.idle": "2025-09-15T17:20:56.709343Z",
          "shell.execute_reply.started": "2025-09-15T17:20:56.619491Z",
          "shell.execute_reply": "2025-09-15T17:20:56.708758Z"
        },
        "id": "3n9ohVimwdT9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "npQT5vdwwdT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_split = 0.2\n",
        "batch_size = 128\n",
        "\n",
        "# data augmentation and normalization\n",
        "transform_train = transforms.Compose([\n",
        "                    transforms.RandomCrop(32, padding=4),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# download dataset\n",
        "train_and_val_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='dataset/',\n",
        "    train=True,\n",
        "    transform=transform_train,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='dataset/',\n",
        "    train=False,\n",
        "    transform=transform_test,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# split train and validation dataset\n",
        "train_size = int((1 - validation_split) * len(train_and_val_dataset))\n",
        "val_size = len(train_and_val_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_and_val_dataset, [train_size, val_size])\n",
        "\n",
        "# create dataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_num = len(test_dataset)\n",
        "test_steps = len(test_loader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:20:56.710947Z",
          "iopub.execute_input": "2025-09-15T17:20:56.711171Z",
          "iopub.status.idle": "2025-09-15T17:21:02.244060Z",
          "shell.execute_reply.started": "2025-09-15T17:20:56.711154Z",
          "shell.execute_reply": "2025-09-15T17:21:02.243410Z"
        },
        "id": "4WprgXfzwdT9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create teacher and student models\n",
        "### Define BottleNeck for ResNet50"
      ],
      "metadata": {
        "id": "dz3sXl-pwdT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv3 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel * self.expansion, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:02.244775Z",
          "iopub.execute_input": "2025-09-15T17:21:02.245043Z",
          "iopub.status.idle": "2025-09-15T17:21:02.252293Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.245018Z",
          "shell.execute_reply": "2025-09-15T17:21:02.251546Z"
        },
        "id": "xNQHKkcVwdT9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Resifual Block"
      ],
      "metadata": {
        "id": "OIZdxOh-wdT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1, downsample=None, **kwargs):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(in_channels=out_channel, out_channels=out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:02.253067Z",
          "iopub.execute_input": "2025-09-15T17:21:02.253296Z",
          "iopub.status.idle": "2025-09-15T17:21:02.277396Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.253273Z",
          "shell.execute_reply": "2025-09-15T17:21:02.276882Z"
        },
        "id": "wkJimDp7wdT-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define ResNet Model"
      ],
      "metadata": {
        "id": "YKwQR8oKwdT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, blocks_num, num_classes=1000):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channel = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, blocks_num[0])\n",
        "        self.layer2 = self._make_layer(block, 128, blocks_num[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, blocks_num[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, blocks_num[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "    def _make_layer(self, block, channel, block_num, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channel != channel * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channel, channel * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(channel * block.expansion))\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channel, channel, downsample=downsample, stride=stride))\n",
        "        self.in_channel = channel * block.expansion\n",
        "\n",
        "        for _ in range(1, block_num):\n",
        "            layers.append(block(self.in_channel, channel))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Finish the forward pass and return the output layer as well as hidden features.\n",
        "        # 2. The output layer and hidden features will be used later for distilling.\n",
        "        # 3. You can refer to the ResNet structure illustration to finish it.\n",
        "\n",
        "        return x, [feature1, feature2, feature3, feature4]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:02.278077Z",
          "iopub.execute_input": "2025-09-15T17:21:02.278332Z",
          "iopub.status.idle": "2025-09-15T17:21:02.301112Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.278307Z",
          "shell.execute_reply": "2025-09-15T17:21:02.300587Z"
        },
        "id": "neQ5KljZwdT-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define ResNet50 and Resnet18"
      ],
      "metadata": {
        "id": "mOy4lBgSwdT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "\n",
        "def resnet50(num_classes=10):\n",
        "    return ResNet(BottleNeck, [3, 4, 6, 3], num_classes=num_classes)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:02.301868Z",
          "iopub.execute_input": "2025-09-15T17:21:02.302108Z",
          "iopub.status.idle": "2025-09-15T17:21:02.321736Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.302092Z",
          "shell.execute_reply": "2025-09-15T17:21:02.321258Z"
        },
        "id": "WmkTpoYzwdT-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Teacher Model (ResNet50)"
      ],
      "metadata": {
        "id": "4vzi6uxFwdT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Teacher = resnet50(num_classes=10)  # commment out this line if loading trained teacher model\n",
        "# Teacher = torch.load('Teacher.pt', weights_only=False)  # loading trained teacher model\n",
        "Teacher = Teacher.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:02.322350Z",
          "iopub.execute_input": "2025-09-15T17:21:02.322519Z",
          "iopub.status.idle": "2025-09-15T17:21:04.197301Z",
          "shell.execute_reply.started": "2025-09-15T17:21:02.322505Z",
          "shell.execute_reply": "2025-09-15T17:21:04.196547Z"
        },
        "id": "1UaF4WGXwdT-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "summary(Teacher)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dmwXM_WtwdT_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Student Model (ResNet18)"
      ],
      "metadata": {
        "id": "BZ4wlBakwdT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Student = resnet18(num_classes=10)  # commment out this line if loading trained student model\n",
        "# Student = torch.load('Student.pt', weights_only=False)  # loading trained student model\n",
        "Student = Student.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:04.213631Z",
          "iopub.execute_input": "2025-09-15T17:21:04.213935Z",
          "iopub.status.idle": "2025-09-15T17:21:04.400068Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.213911Z",
          "shell.execute_reply": "2025-09-15T17:21:04.399483Z"
        },
        "id": "QsBS9LxPwdT_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "summary(Student)"
      ],
      "metadata": {
        "trusted": true,
        "id": "OJ8nTtDswdT_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define training function"
      ],
      "metadata": {
        "id": "qF1RPSfrwdT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_from_scratch(model, train_loader, val_loader, epochs, learning_rate, device, model_name):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
        "\n",
        "    loss = []\n",
        "    train_error=[]\n",
        "    val_error = []\n",
        "    valdation_error = []\n",
        "    train_loss = []\n",
        "    valdation_loss = []\n",
        "    train_accuraacy = []\n",
        "    valdation_accuracy= []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        valid_acc = 0.0\n",
        "        correct = 0.\n",
        "        total = 0.\n",
        "        V_correct = 0.\n",
        "        V_total = 0.\n",
        "\n",
        "        model.train()\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits, hidden = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            pred = logits.data.max(1, keepdim=True)[1]\n",
        "            correct += np.sum(np.squeeze(pred.eq(labels.data.view_as(pred))).cpu().numpy())\n",
        "            total += images.size(0)\n",
        "            train_acc =  correct/total\n",
        "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "                val_images, val_labels = val_data\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "                outputs, hidden_outputs = model(val_images)\n",
        "                loss = criterion(outputs, val_labels)\n",
        "                valid_loss += loss.item() * val_images.size(0)\n",
        "                pred = outputs.data.max(1, keepdim=True)[1]\n",
        "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
        "                V_total += val_images.size(0)\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_error.append(train_loss)\n",
        "        valid_loss = valid_loss / len(val_loader.dataset)\n",
        "        val_error.append(valid_loss)\n",
        "        train_accuraacy.append( correct / total)\n",
        "        valdation_accuracy.append(V_correct / V_total)\n",
        "\n",
        "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
        "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
        "\n",
        "    torch.save(model, f'{model_name}.pt')\n",
        "    print(f'{model_name}.pt is saved')\n",
        "\n",
        "    print('Finished Training')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:04.411049Z",
          "iopub.execute_input": "2025-09-15T17:21:04.411876Z",
          "iopub.status.idle": "2025-09-15T17:21:04.429748Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.411856Z",
          "shell.execute_reply": "2025-09-15T17:21:04.429207Z"
        },
        "id": "sYihMy4lwdT_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define testing function"
      ],
      "metadata": {
        "id": "rJihXOROwdT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader ,device, type=None):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    acc = 0.0\n",
        "    test_loss = 0.0\n",
        "\n",
        "    if type == None:\n",
        "        model.eval()\n",
        "    elif type == 'distiller':\n",
        "        model.eval()\n",
        "        model.teacher.eval()\n",
        "        model.student.eval()\n",
        "    else:\n",
        "       raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_bar = tqdm(test_loader, file=sys.stdout)\n",
        "        for test_data in test_bar:\n",
        "            test_images, test_labels = test_data\n",
        "            test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
        "            if type == None:\n",
        "                outputs, features = model(test_images)\n",
        "                loss = criterion(outputs, test_labels)\n",
        "            elif type == 'distiller':\n",
        "                outputs, loss = model(test_images, test_labels)\n",
        "            else:\n",
        "                raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "            predict_y = torch.max(outputs, dim=1)[1]\n",
        "            acc += torch.eq(predict_y, test_labels.to(device)).sum().item()\n",
        "            test_loss += loss.item()\n",
        "            test_bar.desc = \"test\"\n",
        "\n",
        "    test_accurate = acc / test_num\n",
        "    print('test_loss: %.3f  test_accuracy: %.3f' %(test_loss / test_steps, test_accurate * 100))\n",
        "    return test_loss / test_steps, test_accurate * 100."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:04.430762Z",
          "iopub.execute_input": "2025-09-15T17:21:04.431037Z",
          "iopub.status.idle": "2025-09-15T17:21:04.452490Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.431014Z",
          "shell.execute_reply": "2025-09-15T17:21:04.451992Z"
        },
        "id": "IMcS6k_lwdT_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Teacher and Student model from scratch"
      ],
      "metadata": {
        "id": "AOCKqaHXwdUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide the epochs and learning rate\n",
        "train_from_scratch(Teacher, train_loader, val_loader, epochs= , learning_rate= , device=device, model_name=\"Teacher\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:04.453203Z",
          "iopub.execute_input": "2025-09-15T17:21:04.453428Z",
          "iopub.status.idle": "2025-09-15T17:21:04.473303Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.453399Z",
          "shell.execute_reply": "2025-09-15T17:21:04.472761Z"
        },
        "id": "MhWE8HSbwdUA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "T_loss, T_accuracy = test(Teacher, test_loader, device=device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:21:04.473894Z",
          "iopub.execute_input": "2025-09-15T17:21:04.474123Z",
          "iopub.status.idle": "2025-09-15T17:21:17.055237Z",
          "shell.execute_reply.started": "2025-09-15T17:21:04.474108Z",
          "shell.execute_reply": "2025-09-15T17:21:17.054314Z"
        },
        "id": "_PWsWuLqwdUA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide the epochs and learning rate\n",
        "train_from_scratch(Student, train_loader, val_loader, epochs= , learning_rate= , device=device, model_name=\"Student\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "L43plN89wdUA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "S_loss, S_accuracy = test(Student, test_loader, device=device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:29:33.367451Z",
          "iopub.execute_input": "2025-09-15T17:29:33.367646Z",
          "iopub.status.idle": "2025-09-15T17:29:37.666896Z",
          "shell.execute_reply.started": "2025-09-15T17:29:33.367631Z",
          "shell.execute_reply": "2025-09-15T17:29:37.666154Z"
        },
        "id": "HJRhHt-qwdUA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define distillation\n",
        "\n",
        "### Define the loss functions"
      ],
      "metadata": {
        "id": "bmoN20JuwdUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finish the loss function for response-based distillation.\n",
        "def loss_re():\n",
        "    T = # Set temperature parameter\n",
        "    alpha = # Set weighting parameter\n",
        "\n",
        "    # Implement loss calculation\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:29:37.667767Z",
          "iopub.execute_input": "2025-09-15T17:29:37.668077Z",
          "iopub.status.idle": "2025-09-15T17:29:37.672753Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.668052Z",
          "shell.execute_reply": "2025-09-15T17:29:37.672224Z"
        },
        "id": "2Jjd5o-KwdUA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Finish the loss function for feature-based distillation.\n",
        "def loss_fe():\n",
        "\n",
        "    # Implement loss calculation whatever you prefer\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:29:37.692345Z",
          "iopub.execute_input": "2025-09-15T17:29:37.692627Z",
          "iopub.status.idle": "2025-09-15T17:29:37.712250Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.692603Z",
          "shell.execute_reply": "2025-09-15T17:29:37.711759Z"
        },
        "id": "otjdqnDFwdUA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Distillation Framework"
      ],
      "metadata": {
        "id": "KhIgoti0wdUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Distiller(nn.Module):\n",
        "    def __init__(self, teacher, student, type):\n",
        "        super(Distiller, self).__init__()\n",
        "\n",
        "        # 1. Finish the __init__ method.\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        # 2. Finish the forward pass.\n",
        "\n",
        "        if self.type == 'response':\n",
        "            loss_distill = # call the loss_re()\n",
        "        elif self.type == 'feature':\n",
        "            loss_distill = # call the loss_re()\n",
        "        else:\n",
        "            raise ValueError(f'Error: only support response-based and feature-based distillation')\n",
        "\n",
        "        return student_logits, loss_distill"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:29:37.712911Z",
          "iopub.execute_input": "2025-09-15T17:29:37.713139Z",
          "iopub.status.idle": "2025-09-15T17:29:37.738648Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.713114Z",
          "shell.execute_reply": "2025-09-15T17:29:37.738135Z"
        },
        "id": "lPkIXEXPwdUA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training function"
      ],
      "metadata": {
        "id": "lQHEAueSwdUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_distillation(distiller, student, train_loader, val_loader, epochs, learning_rate, device):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    # define the parameter the optimizer used\n",
        "    optimizer = torch.optim.Adam( , lr=learning_rate)\n",
        "\n",
        "    loss = []\n",
        "    train_error=[]\n",
        "    val_error = []\n",
        "    valdation_error = []\n",
        "    train_loss = []\n",
        "    valdation_loss = []\n",
        "    train_accuraacy = []\n",
        "    valdation_accuracy= []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        distiller.train()\n",
        "        distiller.teacher.train()\n",
        "        distiller.student.train()\n",
        "\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        valid_acc  = 0.0\n",
        "        correct = 0.\n",
        "        total = 0.\n",
        "        V_correct = 0.\n",
        "        V_total = 0.\n",
        "        train_bar = tqdm(train_loader, file=sys.stdout)\n",
        "        for step, data in enumerate(train_bar):\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs, loss = distiller(images, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "            pred = outputs.data.max(1, keepdim=True)[1]\n",
        "            result = pred.eq(labels.data.view_as(pred))\n",
        "            result = np.squeeze(result.cpu().numpy())\n",
        "            correct += np.sum(result)\n",
        "            total += images.size(0)\n",
        "            train_bar.desc = \"train epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        distiller.eval()\n",
        "        distiller.teacher.eval()\n",
        "        distiller.student.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader, file=sys.stdout)\n",
        "            for val_data in val_bar:\n",
        "\n",
        "                val_images, val_labels = val_data\n",
        "                val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
        "\n",
        "                outputs, loss = distiller(val_images, val_labels)\n",
        "\n",
        "                valid_loss += loss.item() * val_images.size(0)\n",
        "                pred = outputs.max(1, keepdim=True)[1]\n",
        "                V_correct += np.sum(np.squeeze(pred.eq(val_labels.data.view_as(pred))).cpu().numpy())\n",
        "                V_total += val_images.size(0)\n",
        "                val_bar.desc = \"valid epoch[{}/{}]\".format(epoch + 1, epochs)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_error.append(train_loss)\n",
        "        valid_loss = valid_loss / len(val_loader.dataset)\n",
        "        val_error.append(valid_loss)\n",
        "        train_accuraacy.append( correct / total)\n",
        "        valdation_accuracy.append(V_correct / V_total)\n",
        "\n",
        "        print('\\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(train_loss, valid_loss))\n",
        "        print('\\tTrain Accuracy: %.3fd%% (%2d/%2d)\\tValdation Accuracy: %.3fd%% (%2d/%2d) '% (100. * correct / total, correct, total, 100. * V_correct / V_total, V_correct, V_total))\n",
        "\n",
        "    print('Finished Distilling')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:29:37.739468Z",
          "iopub.execute_input": "2025-09-15T17:29:37.739676Z",
          "iopub.status.idle": "2025-09-15T17:29:37.757328Z",
          "shell.execute_reply.started": "2025-09-15T17:29:37.739661Z",
          "shell.execute_reply": "2025-09-15T17:29:37.756798Z"
        },
        "id": "3sIn7IJXwdUB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response-based distillation"
      ],
      "metadata": {
        "id": "At2fwU4LwdUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide the epochs and learning rate\n",
        "Student_re = resnet18(num_classes=10)\n",
        "Student_re = Student_re.to(device)\n",
        "distiller_re = Distiller(Teacher, Student_re, type='response')\n",
        "train_distillation(distiller_re, Student_re, train_loader, val_loader, epochs= , learning_rate= , device=device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WRN7odFawdUB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "reS_loss, reS_accuracy = test(distiller_re, test_loader, type='distiller', device=device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T17:46:23.908252Z",
          "iopub.execute_input": "2025-09-15T17:46:23.908450Z",
          "iopub.status.idle": "2025-09-15T17:46:37.767639Z",
          "shell.execute_reply.started": "2025-09-15T17:46:23.908424Z",
          "shell.execute_reply": "2025-09-15T17:46:37.767023Z"
        },
        "id": "uSwU5ooswdUO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature-based distillation"
      ],
      "metadata": {
        "id": "qdisKpMOwdUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide the epochs and learning rate\n",
        "Student_fe = resnet18(num_classes=10)\n",
        "Student_fe = Student_fe.to(device)\n",
        "distiller_fe = Distiller(Teacher, Student_fe, type='feature')\n",
        "train_distillation(distiller_fe, Student_fe, train_loader, val_loader, epochs= , learning_rate= , device=device)"
      ],
      "metadata": {
        "trusted": true,
        "id": "kpshhQrNwdUP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ftS_loss, ftS_accuracy = test(distiller_fe, test_loader, type='distiller', device=device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T18:12:41.349535Z",
          "iopub.execute_input": "2025-09-15T18:12:41.350107Z",
          "iopub.status.idle": "2025-09-15T18:12:56.380748Z",
          "shell.execute_reply.started": "2025-09-15T18:12:41.350082Z",
          "shell.execute_reply": "2025-09-15T18:12:56.380147Z"
        },
        "id": "zM9-xs6SwdUP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result and Comparison"
      ],
      "metadata": {
        "id": "4X7OsAvhwdUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Teacher from scratch: loss = {T_loss:.2f}, accuracy = {T_accuracy:.2f}')\n",
        "print(f'Student from scratch: loss = {S_loss:.2f}, accuracy = {S_accuracy:.2f}')\n",
        "print(f'Response-based student: loss = {reS_loss:.2f}, accuracy = {reS_accuracy:.2f}')\n",
        "print(f'Featured-based student: loss = {ftS_loss:.2f}, accuracy = {ftS_accuracy:.2f}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-09-15T18:12:56.381931Z",
          "iopub.execute_input": "2025-09-15T18:12:56.382324Z",
          "iopub.status.idle": "2025-09-15T18:12:56.387139Z",
          "shell.execute_reply.started": "2025-09-15T18:12:56.382306Z",
          "shell.execute_reply": "2025-09-15T18:12:56.386278Z"
        },
        "id": "nsK1wsDmwdUP"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}