{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "727a2258",
   "metadata": {},
   "source": [
    "# Lab3 Model Quantization\n",
    "## Setup\n",
    "### Install python package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54529209",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install torchinfo\n",
    "!pip install torchsummary\n",
    "!pip install torchvision\n",
    "!pip install tqdm\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a5df7e",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import platform\n",
    "import warnings\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.ao.quantization as tq\n",
    "\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Select device\n",
    "DEFAULT_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Ignore warnings in Pytorch2.8 when using torch.ao.quantization\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Set quantization backend based on CPU architecture\n",
    "machine = platform.machine().lower()\n",
    "if \"x86\" in machine or \"amd64\" in machine:\n",
    "    torch.backends.quantized.engine = 'fbgemm'\n",
    "elif \"arm\" in machine or \"aarch64\" in machine:\n",
    "    torch.backends.quantized.engine = 'qnnpack'\n",
    "else:\n",
    "    print(\"Unsupported machine:\", machine)\n",
    "\n",
    "# Check environment information\n",
    "print(\"Pytorch version:\", torch.__version__)\n",
    "print(f\"Using {torch.backends.quantized.engine} backend {machine}\")\n",
    "print(\"Using device:\", DEFAULT_DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eabdfae",
   "metadata": {},
   "source": [
    "### Load CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "    source, batch_size: int, transform, eval_transform=None,\n",
    "    root: str = \"data\", split_ratio: float = 0.1\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    if eval_transform is None:\n",
    "        eval_transform = transform\n",
    "\n",
    "    trainset = source(root=root, train=True, download=True, transform=transform)\n",
    "    testset  = source(root=root, train=False, download=True, transform=eval_transform)\n",
    "\n",
    "    val_len = int(split_ratio * len(trainset))\n",
    "    train_len = len(trainset) - val_len\n",
    "    trainset, valset = torch.utils.data.random_split(trainset, [train_len, val_len])\n",
    "\n",
    "    loader_kwargs = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    trainloader = DataLoader(trainset, shuffle=True, **loader_kwargs)\n",
    "    valloader  = DataLoader(valset, shuffle=True, **loader_kwargs)\n",
    "    testloader = DataLoader(testset, shuffle=False, **loader_kwargs)\n",
    "\n",
    "    return trainloader, valloader, testloader\n",
    "\n",
    "def get_cifar10_loaders(batch_size: int, root=\"data/cifar10\", split_ratio: float = 0.1):\n",
    "    \"\"\"\n",
    "    Create CIFAR-10 training / validation / testing dataloaders.\n",
    "    \n",
    "    Args:\n",
    "        batch_size (int): Number of samples per mini-batch.\n",
    "        root (str): Path to download/load CIFAR-10 dataset.\n",
    "        split_ratio (float): Fraction of training set to use for validation.\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, val_loader, test_loader (torch.utils.data.DataLoader)\n",
    "    \"\"\"\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        ##### YOUR CODE HERE #####\n",
    "        # Data augmentation for training\n",
    "\n",
    "    ])\n",
    "\n",
    "    eval_transform = transforms.Compose([\n",
    "        ##### YOUR CODE HERE #####\n",
    "        # Evaluation transform\n",
    "\n",
    "    ])\n",
    "\n",
    "    return get_loaders(\n",
    "        datasets.CIFAR10, batch_size, train_transform,\n",
    "        eval_transform=eval_transform, root=root, split_ratio=split_ratio\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \"\"\" You can adjust the numbers below \"\"\"\n",
    "    BATCH_SIZE = 64\n",
    "    VAL_TRAIN_SPLIT_RATIO = 0.1\n",
    "    \n",
    "    train_loader, val_loader, test_loader = get_cifar10_loaders(batch_size=BATCH_SIZE, split_ratio=VAL_TRAIN_SPLIT_RATIO)\n",
    "    print(f\"CIFAR-10: train={len(train_loader.dataset)}, \"\n",
    "            f\"val={len(val_loader.dataset)}, \"\n",
    "            f\"test={len(test_loader.dataset)}, \"\n",
    "            f\"shape={train_loader.dataset[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9276f7",
   "metadata": {},
   "source": [
    "## Model Preparation\n",
    "### Implement ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fdbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizableBasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    BasicBlock for ResNet with quantization support.\n",
    "    \"\"\"\n",
    "\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        # ----- Convolution + BatchNorm + ReLU -----\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        # FloatFunctional() allows fused add+relu in quantized models\n",
    "        self.add_relu = nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        ##### YOUR CODE HERE #####\n",
    "        # out = add + relu (skip connection)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def fuse_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Fuse Conv-BN-ReLU for quantization.\n",
    "        \"\"\"\n",
    "\n",
    "        ##### YOUR CODE HERE #####\n",
    "        # Fuse conv+bn+relu modules\n",
    "\n",
    "        if self.downsample:\n",
    "            ##### YOUR CODE HERE #####\n",
    "            # Fuse downsample conv+bn if exists\n",
    "\n",
    "            pass\n",
    "\n",
    "\n",
    "class QuantizableBottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck block for ResNet with quantization support.\n",
    "    \"\"\"\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        # 1x1 reduce\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # 3x3 conv\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # 1x1 expand\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        self.relu1 = nn.ReLU(inplace=False)\n",
    "        self.relu2 = nn.ReLU(inplace=False)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        # FloatFunctional for quantized skip connection\n",
    "        self.skip_add_relu = nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        ##### YOUR CODE HERE #####\n",
    "        # out = add + relu (skip connection)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "    def fuse_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Fuse Conv-BN-ReLU for quantization.\n",
    "        \"\"\"\n",
    "        ##### YOUR CODE HERE #####\n",
    "        # Fuse conv+bn+relu modules\n",
    "\n",
    "        if self.downsample:\n",
    "            ##### YOUR CODE HERE #####\n",
    "            # Fuse downsample conv+bn if exists\n",
    "\n",
    "            pass\n",
    "\n",
    "\n",
    "class QuantizableResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet model adapted for CIFAR-10 and quantization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.inplanes = 64\n",
    "\n",
    "        # CIFAR-10 uses 3x3 conv instead of 7x7\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.maxpool = nn.Identity() # no pooling for CIFAR-10\n",
    "\n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        # Quantization stubs\n",
    "        self.quant = tq.QuantStub()\n",
    "        self.dequant = tq.DeQuantStub()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        \"\"\"\n",
    "        Helper function to build ResNet layers.\n",
    "        \"\"\"\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        ##### YOUR CODE HERE #####\n",
    "        # Quantize input\n",
    "\n",
    "        # conv1 -> bn1 -> relu\n",
    "\n",
    "\n",
    "        # Pass through 4 residual layers\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        # Classification head\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        ##### YOUR CODE HERE #####\n",
    "        # Dequantize output\n",
    "\n",
    "        return x\n",
    "\n",
    "    def fuse_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Fuse Conv-BN-ReLU layers in ResNet.\n",
    "        \"\"\"\n",
    "        ##### YOUR CODE HERE #####\n",
    "        # Fuse conv+bn+relu modules\n",
    "\n",
    "        for m in self.modules():\n",
    "            if type(m) is QuantizableBottleneck or type(m) is QuantizableBasicBlock:\n",
    "                m.fuse_model()\n",
    "\n",
    "\n",
    "def resnet50_cifar10() -> QuantizableResNet:\n",
    "    \"\"\"\n",
    "    Construct a ResNet-50 for CIFAR-10 with quantization support.\n",
    "    \"\"\"\n",
    "    model = QuantizableResNet(QuantizableBottleneck, [3, 4, 6, 3], num_classes=10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87da267",
   "metadata": {},
   "source": [
    "### Inspect Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbde932",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = resnet50_cifar10()\n",
    "    summary(model, (3, 32, 32), device= 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97db47",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d97f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_filename(filename: str, existed: str = \"keep_both\") -> str:\n",
    "    if existed == \"overwrite\":\n",
    "        pass\n",
    "    elif existed == \"keep_both\":\n",
    "        base, ext = os.path.splitext(filename)\n",
    "        cnt = 1\n",
    "        while os.path.exists(filename):\n",
    "            filename = f\"{base}-{cnt}{ext}\"\n",
    "            cnt += 1\n",
    "    elif existed == \"raise\" and os.path.exists(filename):\n",
    "        raise FileExistsError(f\"{filename} already exists.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown value for 'existed': {existed}\")\n",
    "    return filename\n",
    "\n",
    "def plot_loss_accuracy(train_loss, train_acc, val_loss, val_acc, filename=\"loss_accuracy.png\"):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.plot(train_loss, color=\"tab:blue\")\n",
    "    ax1.plot(val_loss, color=\"tab:red\")\n",
    "    ax1.legend([\"Training\", \"Validation\"])\n",
    "    ax1.set_title(\"Loss\")\n",
    "\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.plot(train_acc, color=\"tab:blue\")\n",
    "    ax2.plot(val_acc, color=\"tab:red\")\n",
    "    ax2.legend([\"Training\", \"Validation\"])\n",
    "    ax2.set_title(\"Accuracy\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    filename = preprocess_filename(filename)\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    plt.savefig(filename)\n",
    "    print(f\"Plot saved at {filename}\")\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, filename=\"conf_matrix.png\"):\n",
    "    classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        conf_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=classes,\n",
    "        yticklabels=classes,\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix for CIFAR-10 Classification\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = preprocess_filename(filename)\n",
    "    plt.savefig(filename)\n",
    "    print(f\"Confusion matrix saved to {filename}\")\n",
    "\n",
    "def save_model(model, filename: str, verbose: bool = True, existed: str = \"keep_both\") -> None:\n",
    "    filename = preprocess_filename(filename, existed)\n",
    "\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    if verbose:\n",
    "        print(f\"Model saved at {filename} ({os.path.getsize(filename) / 1e6} MB)\")\n",
    "    else:\n",
    "        print(f\"Model saved at {filename}\")\n",
    "\n",
    "def load_model(model, filename: str, qconfig=None, fuse_modules: bool = False, verbose: bool = True) -> torch.nn.Module:\n",
    "    if fuse_modules and hasattr(model, \"fuse_module\"):\n",
    "        print(\"Fusing modules\")\n",
    "        model.to('cpu').eval()\n",
    "        model.fuse_model()\n",
    "    \n",
    "    if qconfig is not None:\n",
    "        model.qconfig = qconfig\n",
    "        qconfig_dict = {\"\": qconfig}\n",
    "        model2 = copy.deepcopy(model)\n",
    "        model_prepared = tq.prepare(model2, qconfig_dict)\n",
    "        model_int8 = tq.convert(model_prepared)\n",
    "        model_int8.load_state_dict(torch.load(filename, map_location='cpu', weights_only=False))\n",
    "        model_int8.eval()\n",
    "    else:\n",
    "        device = DEFAULT_DEVICE if qconfig is None else 'cpu'\n",
    "        model.load_state_dict(torch.load(filename, map_location=device, weights_only=False))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Model loaded from {filename} ({os.path.getsize(filename) / 1e6} MB)\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6f807",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "### Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b367384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device=DEFAULT_DEVICE):\n",
    "    running_loss = 0\n",
    "    total, correct = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loop = tqdm(dataloader, desc=\"Evaluating\", leave=True)\n",
    "\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predicted = torch.argmax(output, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        loop.set_postfix(\n",
    "            loss=running_loss / (total / images.shape[0]), accuracy=correct / total\n",
    "        )\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = correct / total * 100\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "    return avg_loss, accuracy, conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1417fafa",
   "metadata": {},
   "source": [
    "### Custom Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### YOUR CODE HERE #####\n",
    "# Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d9293",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b2cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader,\n",
    "                epochs=10, lr=0.1,\n",
    "                is_qat: bool = False, device=DEFAULT_DEVICE):\n",
    "    \"\"\"\n",
    "    Train the model across multiple epochs and validate after each epoch.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Model to train.\n",
    "        train_loader (DataLoader): Training data loader.\n",
    "        val_loader (DataLoader): Validation data loader.\n",
    "        epochs (int): Number of epochs to train.\n",
    "        lr (float): Learning rate.\n",
    "        is_qat (bool): Whether this is QAT training.\n",
    "        device (str): Training device.\n",
    "    \n",
    "    Returns:\n",
    "        model (nn.Module): Trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    ##### YOUR CODE HERE #####\n",
    "    # Implement ypur criterion, optimizer, and scheduler\n",
    "\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    train_loss_history, train_acc_history = [], []\n",
    "    val_loss_history, val_acc_history = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            ##### YOUR CODE HERE #####\n",
    "            # 1. Zero optimizer gradients\n",
    "\n",
    "            # 2. Forward pass\n",
    "\n",
    "            # 3. Compute loss\n",
    "\n",
    "            # 4. Backward pass\n",
    "\n",
    "            # 5. Optimizer step\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            pbar.set_postfix({\"loss\": running_loss / total})\n",
    "\n",
    "        epoch_train_loss = running_loss / total\n",
    "        epoch_train_acc = correct / total\n",
    "\n",
    "        # ----- Validation -----\n",
    "        ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "        # Save history\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "        train_acc_history.append(epoch_train_acc)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc / 100.0)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | \"\n",
    "              f\"Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc*100:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            if not is_qat:\n",
    "                save_model(model, \"./weights/best_resnet50_cifar10.pth\", existed=\"overwrite\")\n",
    "            else:\n",
    "                save_model(model, \"./weights/QAT_resnet50_cifar10.pth\", existed=\"overwrite\")\n",
    "\n",
    "        if scheduler is not None:\n",
    "            ##### YOUR CODE HERE #####\n",
    "            \n",
    "\n",
    "    # ----- Plot loss/accuracy after training -----\n",
    "    if not is_qat:\n",
    "        plot_file = \"./results/loss_accuracy.png\"\n",
    "    else:\n",
    "        plot_file = \"./results/QAT_loss_accuracy.png\"\n",
    "\n",
    "    plot_loss_accuracy(\n",
    "        train_loss_history, train_acc_history,\n",
    "        val_loss_history, val_acc_history,\n",
    "        filename=plot_file\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dcb2e3",
   "metadata": {},
   "source": [
    "### Hyperparameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cbe1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \"\"\" You can adjust the numbers below \"\"\"\n",
    "    EPOCHS = 20\n",
    "    LEARNING_RATE = 0.1\n",
    "    \n",
    "    model = resnet50_cifar10().to(DEFAULT_DEVICE)\n",
    "    train_model(model, train_loader, val_loader, epochs=EPOCHS, lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566744b",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8616035",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ##### YOUR CODE HERE #####\n",
    "    # Implement your criterion\n",
    "\n",
    "    model = resnet50_cifar10().to(DEFAULT_DEVICE)\n",
    "    model = load_model(model, \"./weights/best_resnet50_cifar10.pth\", verbose=False)\n",
    "    avg_loss, test_acc, conf_matrix = evaluate(model, test_loader, criterion)\n",
    "    print(f\"Test Accuracy: {test_acc:.2f}% | Loss: {avg_loss:.4f}\")\n",
    "    plot_confusion_matrix(conf_matrix, filename=\"./results/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fa08ef",
   "metadata": {},
   "source": [
    "## Post-Training Quantization (PTQ)\n",
    "### Implement Quantization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CusQuantObserver(tq.MinMaxObserver):\n",
    "    \"\"\"\n",
    "    Observer module for your customized customize quantization scheme.\n",
    "    \"\"\"\n",
    "\n",
    "    def scale_approximate(self, scale: float, max_shift_amount=8) -> float:\n",
    "        ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "    def calculate_qparams(self):\n",
    "        \"\"\"Calculates the quantization parameters with scale.\"\"\"\n",
    "        min_val, max_val = self.min_val.item(), self.max_val.item()\n",
    "\n",
    "        \"\"\" Calculate zero_point as in the base class \"\"\"\n",
    "        ##### YOUR CODE HERE #####\n",
    "\n",
    "        \n",
    "        scale = self.scale_approximate(scale)\n",
    "        scale = torch.tensor(scale, dtype=torch.float32)\n",
    "        zero_point = torch.tensor(zero_point, dtype=torch.int64)\n",
    "        return scale, zero_point\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"min_val={self.min_val}, max_val={self.max_val}, scale=CustomQConfig\"\n",
    "\n",
    "\n",
    "class CustomQConfig(Enum):\n",
    "    CusQuant = tq.QConfig(\n",
    "        activation=CusQuantObserver.with_args(\n",
    "            dtype=torch.quint8, qscheme=torch.per_tensor_symmetric\n",
    "        ),\n",
    "        weight=CusQuantObserver.with_args(\n",
    "            dtype=torch.qint8, qscheme=torch.per_tensor_symmetric\n",
    "        ),\n",
    "    )\n",
    "    DEFAULT = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e5d8b",
   "metadata": {},
   "source": [
    "### Evaluate Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(model_fp32, model_int8, dataloader, criterion,\n",
    "                     is_ptq: bool = True,\n",
    "                     fp32_file=\"./weights/best_resnet50_cifar10.pth\",\n",
    "                     int8_file=\"./weights/PTQ_resnet50_cifar10.pth\"\n",
    "                    ):\n",
    "    \n",
    "    device_fp32 = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device_int8 = 'cpu'\n",
    "\n",
    "    model_fp32.to(device_fp32)\n",
    "    model_int8.to(device_int8)\n",
    "\n",
    "\n",
    "    # ----- Test accuracy & loss -----\n",
    "    print(\"Evaluating FP32 model...\")\n",
    "    loss_fp32, acc_fp32, _ = evaluate(model_fp32, dataloader, criterion, device=device_fp32)\n",
    "    print(f\"[FP32] Loss: {loss_fp32:.4f}, Accuracy: {acc_fp32:.2f}%\")\n",
    "\n",
    "    print(\"Evaluating INT8 model...\")\n",
    "    loss_int8, acc_int8, _ = evaluate(model_int8, dataloader, criterion, device=device_int8)\n",
    "    if is_ptq:\n",
    "        print(f\"[PTQ INT8] Loss: {loss_int8:.4f}, Accuracy: {acc_int8:.2f}%\")\n",
    "    else:\n",
    "        print(f\"[QAT INT8] Loss: {loss_int8:.4f}, Accuracy: {acc_int8:.2f}%\")\n",
    "\n",
    "\n",
    "    # ----- Test latency -----\n",
    "    model_fp32.to('cpu')\n",
    "    dummy_input = torch.randn(1, 3, 32, 32).to('cpu')\n",
    "\n",
    "    # FP32\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(1000):\n",
    "            _ = model_fp32(dummy_input)\n",
    "    t1 = time.time()\n",
    "    fp32_time = (t1 - t0) / 1000\n",
    "\n",
    "    # INT8\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(1000):\n",
    "            _ = model_int8(dummy_input)\n",
    "    t1 = time.time()\n",
    "    int8_time = (t1 - t0) / 1000\n",
    "\n",
    "    if is_ptq:\n",
    "        print(f\"[Latency] FP32: {fp32_time*1000:.3f} ms | PTQ INT8: {int8_time*1000:.3f} ms\")\n",
    "    else:\n",
    "        print(f\"[Latency] FP32: {fp32_time*1000:.3f} ms | QAT INT8: {int8_time*1000:.3f} ms\")\n",
    "    print(f\"[Speedup] ~{fp32_time/int8_time:.2f}x faster\")\n",
    "\n",
    "\n",
    "    # ----- Compare file size ----- \n",
    "    if os.path.exists(fp32_file) and os.path.exists(int8_file):\n",
    "        size_fp32 = os.path.getsize(fp32_file) / 1e6\n",
    "        size_int8 = os.path.getsize(int8_file) / 1e6\n",
    "        if is_ptq:\n",
    "            print(f\"[File size] FP32: {size_fp32:.2f} MB | PTQ INT8: {size_int8:.2f} MB\")\n",
    "        else:\n",
    "            print(f\"[File size] FP32: {size_fp32:.2f} MB | QAT INT8: {size_int8:.2f} MB\")\n",
    "        print(f\"[Compression] ~{size_fp32/size_int8:.2f}x smaller\")\n",
    "    else:\n",
    "        print(\"Warning: model files not found. Skipping file size comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40235c5d",
   "metadata": {},
   "source": [
    "### Run PTQ Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb84e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(model, loader, device= 'cpu'):\n",
    "    \"\"\"\n",
    "    Run one pass of calibration on the dataset to collect statistics \n",
    "    for quantization (e.g., min/max values of activations).\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The model prepared for quantization.\n",
    "        loader (DataLoader): Data loader for calibration dataset.\n",
    "        device (str): Device to run calibration on.\n",
    "    \"\"\"\n",
    "    ##### YOUR CODE HERE #####\n",
    "\n",
    "\n",
    "def ptq_quantization():\n",
    "    \"\"\"\n",
    "    Perform Post-Training Quantization (PTQ) on the trained ResNet-50 model.\n",
    "    \n",
    "    Steps:\n",
    "        1. Load CIFAR-10 validation set\n",
    "        2. Load trained FP32 model\n",
    "        3. Fuse model layers\n",
    "        4. Prepare model for PTQ\n",
    "        5. Calibrate using validation data\n",
    "        6. Convert model to INT8\n",
    "        7. Save quantized model\n",
    "    Returns:\n",
    "        model_int8 (nn.Module): The INT8 quantized model after PTQ\n",
    "    \"\"\"\n",
    "    # 1. Data\n",
    "    _, val_loader, _ = get_cifar10_loaders(batch_size=64)\n",
    "\n",
    "    # 2. Load model (FP32 baseline)\n",
    "    fp32_checkpoint = \"./weights/best_resnet50_cifar10.pth\"\n",
    "    model_fp32 = load_model(resnet50_cifar10(), fp32_checkpoint)\n",
    "\n",
    "    ##### YOUR CODE HERE #####\n",
    "    # 3. Fuse layers\n",
    "\n",
    "    # 4. Prepare PTQ\n",
    "\n",
    "    # 5. Calibrate\n",
    "\n",
    "    # 6. Convert to INT8\n",
    "\n",
    "    # 7. Save INT8 model\n",
    "    save_model(model_int8, \"./weights/PTQ_resnet50_cifar10.pth\", existed=\"overwrite\")\n",
    "    \n",
    "    return model_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421305af",
   "metadata": {},
   "source": [
    "### Compare FP32 vs Quantized Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629abfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model_int8 = ptq_quantization()\n",
    "\n",
    "    ##### YOUR CODE HERE #####\n",
    "    # Implement your criterion\n",
    "\n",
    "    fp32_checkpoint = \"./weights/best_resnet50_cifar10.pth\"\n",
    "    model_baseline = load_model(resnet50_cifar10(), fp32_checkpoint, verbose=True)\n",
    "    test_performance(model_baseline, model_int8, test_loader, criterion, is_ptq=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612c665f",
   "metadata": {},
   "source": [
    "## Quantization-Aware Training (QAT)\n",
    "### Run QAT Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4355338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qat_quantization():\n",
    "    \"\"\"\n",
    "    Run Quantization-Aware Training (QAT) workflow on ResNet-50 for CIFAR-10.\n",
    "    \n",
    "    Steps:\n",
    "        0. Prepare CIFAR-10 dataloaders\n",
    "        1. Load pretrained FP32 model\n",
    "        2. Fuse model layers\n",
    "        3. Assign QAT qconfig\n",
    "        4. Prepare model for QAT\n",
    "        5. Train with QAT\n",
    "        6. Convert to INT8 model\n",
    "        7. Save quantized model\n",
    "    Returns:\n",
    "        model_int8 (nn.Module): The INT8 quantized model after QAT\n",
    "    \"\"\"\n",
    "    # 1. Data\n",
    "    train_loader, val_loader, test_loader = get_cifar10_loaders(batch_size=64)\n",
    "\n",
    "    # 2. Load model (FP32 baseline)\n",
    "    fp32_checkpoint = \"./weights/best_resnet50_cifar10.pth\"\n",
    "    model_fp32 = load_model(resnet50_cifar10(), fp32_checkpoint)\n",
    "\n",
    "    ##### YOUR CODE HERE #####\n",
    "    # 3. Fuse layers before QAT\n",
    "\n",
    "    # 4. Set qconfig to enable QAT\n",
    "    \n",
    "    # 5. Prepare model\n",
    "\n",
    "    # 6. Run QAT training\n",
    "    # Use train_model(is_qat=True, ...)\n",
    "\n",
    "    # 7. Convert to INT8\n",
    "\n",
    "    # 8. Save INT8 model\n",
    "    save_model(model_int8, \"./weights/QAT_resnet50_cifar10.pth\", existed=\"overwrite\")\n",
    "\n",
    "    return model_int8\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_int8 = qat_quantization()\n",
    "\n",
    "    ##### YOUR CODE HERE #####\n",
    "    # Implement your criterion\n",
    "\n",
    "    fp32_checkpoint = \"./weights/best_resnet50_cifar10.pth\"\n",
    "    model_baseline = load_model(resnet50_cifar10(), fp32_checkpoint, verbose=False)\n",
    "    test_performance(model_baseline, model_int8, test_loader, criterion, is_ptq=False,\n",
    "                    fp32_file=fp32_checkpoint, int8_file=\"./weights/QAT_resnet50_cifar10.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AOC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
