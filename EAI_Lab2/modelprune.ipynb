{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lk6d9yOhuSkr"
   },
   "source": [
    "## 掛載雲端硬碟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3NTpFfZGuVSx"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEETyGg0uZnb"
   },
   "source": [
    "## 更改檔案所在路徑\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Wum2GQmwucfZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/twccjq88/2025EAI_Project/EAI_Lab2\n"
     ]
    }
   ],
   "source": [
    "# Change to your own folder !!!\n",
    "%cd /home/twccjq88/2025EAI_Project/EAI_Lab2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9NTZ1VEtbV7"
   },
   "source": [
    "## 載入函式庫\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vCvF-fM0tfsq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from models.resnet import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_X_r4dtMuwbh"
   },
   "source": [
    "## 超參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_2NkY0LyuyQh"
   },
   "outputs": [],
   "source": [
    "DATASET = 'cifar10'\n",
    "TEST_BATCH_SIZE = 1000\n",
    "CUDA = True\n",
    "PRUNE_PERCENT = 0.90 # Change your prune ratio!\n",
    "WEIGHT_PATH = '/home/twccjq88/2025EAI_Project/EAI_Lab2/checkpoints/model_lambda_1e-4.pth'\n",
    "PRUNE_PATH = '/home/twccjq88/2025EAI_Project/EAI_Lab2/checkpoints/model_prune.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7z4dkhJwB4Z"
   },
   "source": [
    "## 載入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lpIqnhfKwEcJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22369/2455824156.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(WEIGHT_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING CHECKPOINT /home/twccjq88/2025EAI_Project/EAI_Lab2/checkpoints/model_lambda_1e-4.pth @EPOCH=39, BEST_ACC=0.9115\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "\n",
    "model = ResNet50(num_classes=10)\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "if WEIGHT_PATH:\n",
    "    if os.path.isfile(WEIGHT_PATH):\n",
    "        checkpoint = torch.load(WEIGHT_PATH)\n",
    "        state_dict = checkpoint['state_dict']\n",
    "\n",
    "        cleaned_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            cleaned_key = k.replace('module.', '', 1) if k.startswith('module.') else k\n",
    "            cleaned_state_dict[cleaned_key] = v\n",
    "\n",
    "        model.load_state_dict(cleaned_state_dict)\n",
    "        best_acc = checkpoint.get('best_test_acc', None)\n",
    "        epoch = checkpoint.get('epoch', 'N/A')\n",
    "        print(f'LOADING CHECKPOINT {WEIGHT_PATH} @EPOCH={epoch}, BEST_ACC={best_acc}')\n",
    "    else:\n",
    "        print(\"NO CHECKPOINT FOUND\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srauYOD-1vSp"
   },
   "source": [
    "## Run Pruning\n",
    "#### Collect and sort the absolute scale factors from every BatchNorm layer\n",
    "#### Use the configured PRUNE_PERCENT to pick the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xgtUBaDw1uuR"
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d) and m.weight is not None:\n",
    "        # The downsample shortcut BatchNorm uses affine=False, so skip it because it has no weights\n",
    "        total += m.weight.data.shape[0]\n",
    "\n",
    "bn = torch.zeros(total)\n",
    "index = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d) and m.weight is not None:\n",
    "        size = m.weight.data.shape[0]\n",
    "        bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "        index += size\n",
    "\n",
    "y, i = torch.sort(bn)\n",
    "\n",
    "threshold_index = min(total - 1, int(total * PRUNE_PERCENT))\n",
    "threshold = y[threshold_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66vDWd5BMmph"
   },
   "source": [
    "## Build CONFIG From BatchNorm Layers\n",
    "#### 1. Copy each BatchNorm scale factor (γ)\n",
    "#### 2. Create a mask that keeps values above the threshold and drops the rest\n",
    "#### 3. Sum the mask to obtain the remaining output channels per layer\n",
    "#### 4. Use these values to build the pruned model CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PBklaqUZHnvp"
   },
   "outputs": [],
   "source": [
    "pruned = 0\n",
    "cfg = []  #用來建立剪枝網路的CONFIG\n",
    "cfg_mask = [] #用來幫助剪枝的遮罩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "cfg: [64, 64, 64, 256, 64, 64, 256, 64, 64, 256, 122, 118, 512, 118, 123, 512, 102, 107, 512, 54, 37, 512, 27, 31, 1024, 23, 62, 1024, 3, 3, 1024, 3, 1, 1024, 3, 3, 1024, 3, 3, 1024, 1, 3, 2048, 3, 3, 2048, 3, 3, 2048]\n",
      "======================================================================\n",
      "Pruned parameters: 3,973,494 (3.97M)\n",
      "Original parameters: 23,513,162 (23.51M)\n",
      "Reduction: 83.10%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===== 第一步：建立初始 mask 和 cfg =====\n",
    "for k, m in enumerate(model.modules()):\n",
    "    if isinstance(m, nn.BatchNorm2d) and m.weight is not None:\n",
    "        weight_copy = m.weight.data.clone()\n",
    "        mask = weight_copy.abs().gt(threshold).float().to(weight_copy.device)\n",
    "        \n",
    "        if torch.sum(mask) == 0:\n",
    "            preserve = min(3, mask.numel())\n",
    "            _, idx = torch.topk(weight_copy.abs(), k=preserve, largest=True, sorted=False)\n",
    "            mask[idx] = 1.0\n",
    "        \n",
    "        m.weight.data.mul_(mask)\n",
    "        m.bias.data.mul_(mask)\n",
    "        pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "        cfg.append(int(torch.sum(mask)))\n",
    "        cfg_mask.append(mask.detach().cpu().clone())\n",
    "\n",
    "\n",
    "# ===== 第二步：固定所有 BN3 到原始維度 =====\n",
    "original_output_dims = [256, 512, 1024, 2048]\n",
    "layers = [3, 4, 6, 3]\n",
    "cfg_idx = 1\n",
    "\n",
    "for layer_num, num_blocks in enumerate(layers):\n",
    "    target_dim = original_output_dims[layer_num]\n",
    "    \n",
    "    for b in range(num_blocks):\n",
    "        bn3_idx = cfg_idx + b * 3 + 2\n",
    "        cfg[bn3_idx] = target_dim\n",
    "        cfg_mask[bn3_idx] = torch.ones(target_dim)\n",
    "    \n",
    "    cfg_idx += num_blocks * 3\n",
    "\n",
    "\n",
    "# ===== 第三步：計算結果 =====\n",
    "print(\"=\"*70)\n",
    "print(f'cfg: {cfg}')\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 建立模型並計算參數\n",
    "newmodel = ResNet50(num_classes=10, cfg=cfg)\n",
    "if CUDA:\n",
    "    newmodel.cuda()\n",
    "\n",
    "pruned_params = sum(p.numel() for p in newmodel.parameters())\n",
    "original_params = 23_513_162\n",
    "\n",
    "print(f\"Pruned parameters: {pruned_params:,} ({pruned_params/1e6:.2f}M)\")\n",
    "print(f\"Original parameters: {original_params:,} (23.51M)\")\n",
    "print(f\"Reduction: {(1 - pruned_params/original_params)*100:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ha2BuBl1ifM"
   },
   "source": [
    "## 建立剪枝模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SlWNdj2f1nWs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(122, 118, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(118, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 118, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(118, 123, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(123, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 102, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(102, 107, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(107, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(107, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(54, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(37, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(27, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(31, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(23, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(62, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(1, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(1, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel = ResNet50(num_classes=10, cfg=cfg)\n",
    "newmodel.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned parameters: 3,973,494 (3.97M)\n",
      "Original parameters: 23,513,162 (23.51M)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 檢查參數數量\n",
    "pruned_params = sum(p.numel() for p in newmodel.parameters())\n",
    "original_params = 23_513_162\n",
    "\n",
    "print(f\"Pruned parameters: {pruned_params:,} ({pruned_params/1e6:.2f}M)\")\n",
    "print(f\"Original parameters: {original_params:,} (23.51M)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms9Usgkh1Vbe"
   },
   "source": [
    "### 將原本的模型權重複製到剪枝的模型\n",
    "#### 根據不同層決定要複製什麼權重\n",
    "###### Batch Normalization Layer\n",
    "1.   scale factor\n",
    "2.   bias\n",
    "3.   running mean\n",
    "4.   running variance\n",
    "\n",
    "###### Convolutional Layer\n",
    "1.   weight\n",
    "\n",
    "###### Linear Layer\n",
    "1.   weight\n",
    "2.   bias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hQcKuMDee46V"
   },
   "outputs": [],
   "source": [
    "old_modules = list(model.modules())\n",
    "new_modules = list(newmodel.modules())\n",
    "\n",
    "layer_id_in_cfg = 0\n",
    "start_mask = torch.ones(3) #3為input channel(R,G,B)\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "bn_count = 0\n",
    "block_input_mask = torch.ones(3)  # 用於記錄每個 block 開始時的輸入通道遮罩（用於 downsample 分支）\n",
    "block_output_mask = None  # 用於記錄每個 block 結束時的輸出通道遮罩（BN3 的遮罩，用於 downsample 輸出）\n",
    "\n",
    "for layer_id in range(len(old_modules)):\n",
    "\n",
    "    m0 = old_modules[layer_id]\n",
    "    m1 = new_modules[layer_id]\n",
    "\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        # downsample shortcut 的 BN 設為 affine=False，沒有 weight/bias\n",
    "        # downsample BN 在 BN3 之後被處理，所以應該用 block_output_mask (BN3 的遮罩)\n",
    "        if m0.weight is None:\n",
    "            if block_output_mask is not None:\n",
    "                idx = torch.nonzero(block_output_mask).squeeze().long().cpu()\n",
    "                if idx.ndim == 0:\n",
    "                    idx = idx.unsqueeze(0)\n",
    "                m1.running_mean = m0.running_mean.cpu().index_select(0, idx).to(m1.running_mean.device).clone()\n",
    "                m1.running_var = m0.running_var.cpu().index_select(0, idx).to(m1.running_var.device).clone()\n",
    "            continue\n",
    "\n",
    "        #### 找出遮罩中非零元素的index ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        current_mask = cfg_mask[layer_id_in_cfg]\n",
    "        \n",
    "        # 在每個 block 的第一個 BN 時（bn_count%3==1），記錄該 block 的輸入通道遮罩\n",
    "        # 在每個 block 的第三個 BN 時（bn_count%3==0），保存該 block 的輸出遮罩\n",
    "        # 注意: bn_count 在這裡尚未處理當前 BN,範圍是 [0, 1, 2, 3, 4, 5, ...]\n",
    "        # bn_count=0: 即將處理 Conv1.BN (0%3=0, 但 layer_id_in_cfg==0 是特例)\n",
    "        # bn_count=1: 即將處理 Block0.BN1 → 1%3=1 (BN1) ✓ 記錄輸入\n",
    "        # bn_count=2: 即將處理 Block0.BN2 → 2%3=2 (BN2)\n",
    "        # bn_count=3: 即將處理 Block0.BN3 → 3%3=0 (BN3) ✓ 記錄輸出\n",
    "        if bn_count % 3 == 1:  # bn_count=1,4,7,... (block 的第一個 BN)\n",
    "            if layer_id_in_cfg == 0:\n",
    "                # 第一個 BN（conv1 後面）使用其自己的輸出作為後續 block 的輸入\n",
    "                block_input_mask = current_mask.clone()\n",
    "            else:\n",
    "                # 後續 block 的輸入是上一個 BN 的輸出\n",
    "                block_input_mask = start_mask.clone()\n",
    "        \n",
    "        # 在 BN3 時（block 的第 3 個 BN），保存該 block 的輸出遮罩\n",
    "        # 供後續 downsample 層使用\n",
    "        if bn_count % 3 == 0 and bn_count > 0:  # bn_count=3,6,9,... (block 的第三個 BN，即 BN3)\n",
    "            block_output_mask = current_mask.clone()\n",
    "        \n",
    "        bn_count += 1\n",
    "        \n",
    "        idx = torch.nonzero(current_mask).squeeze().long()\n",
    "        if idx.ndim == 0:\n",
    "            idx = idx.unsqueeze(0)\n",
    "        idx = idx.cpu()\n",
    "\n",
    "        #### 複製weight, bias, running mean,and running variance ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        m1.weight.data = m0.weight.data.cpu().index_select(0, idx).to(m1.weight.device).clone()\n",
    "        m1.bias.data = m0.bias.data.cpu().index_select(0, idx).to(m1.bias.device).clone()\n",
    "        m1.running_mean = m0.running_mean.cpu().index_select(0, idx).to(m1.running_mean.device).clone()\n",
    "        m1.running_var = m0.running_var.cpu().index_select(0, idx).to(m1.running_var.device).clone()\n",
    "\n",
    "        layer_id_in_cfg += 1\n",
    "        start_mask = end_mask.clone()\n",
    "\n",
    "        #最後一層連接層不做修改\n",
    "        if layer_id_in_cfg < len(cfg_mask):\n",
    "            end_mask = cfg_mask[layer_id_in_cfg]\n",
    "        else:\n",
    "            end_mask = torch.ones_like(start_mask)\n",
    "\n",
    "\n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        if isinstance(old_modules[layer_id + 1], nn.BatchNorm2d) and old_modules[layer_id + 1].weight is not None:\n",
    "            idx0 = torch.nonzero(start_mask).squeeze().long().cpu()\n",
    "            idx1 = torch.nonzero(end_mask).squeeze().long().cpu()\n",
    "\n",
    "            #### 複製weight ####\n",
    "            ################################################\n",
    "            #          請填空          #\n",
    "            ################################################\n",
    "            if idx0.ndim == 0:\n",
    "                idx0 = idx0.unsqueeze(0)\n",
    "            if idx1.ndim == 0:\n",
    "                idx1 = idx1.unsqueeze(0)\n",
    "            w = m0.weight.data.cpu().index_select(1, idx0)\n",
    "            w = w.index_select(0, idx1)\n",
    "            m1.weight.data = w.to(m1.weight.device).clone()\n",
    "\n",
    "\n",
    "\n",
    "        # downsample 層也需根據剪枝結果調整輸入／輸出通道\n",
    "        # downsample Conv 在 BN3 之後被處理，所以應該用 block_output_mask (BN3 的遮罩) 作為輸出通道\n",
    "        # 輸入應該是 block 開始時的通道數 (block_input_mask)\n",
    "        # 輸出應該是 block 結束時的通道數 (block_output_mask，即 BN3 的遮罩)\n",
    "        else:\n",
    "            input_idx = torch.nonzero(block_input_mask).squeeze().long()\n",
    "            output_idx = torch.nonzero(block_output_mask).squeeze().long()\n",
    "            if input_idx.ndim == 0:\n",
    "                input_idx = input_idx.unsqueeze(0)\n",
    "            if output_idx.ndim == 0:\n",
    "                output_idx = output_idx.unsqueeze(0)\n",
    "            input_idx = input_idx.cpu()\n",
    "            output_idx = output_idx.cpu()\n",
    "            w = m0.weight.data.cpu().index_select(1, input_idx)\n",
    "            w = w.index_select(0, output_idx)\n",
    "            m1.weight.data = w.to(m1.weight.device).clone()\n",
    "\n",
    "\n",
    "    elif isinstance(m0, nn.Linear):\n",
    "\n",
    "        idx0 = torch.nonzero(start_mask).squeeze().long().cpu()\n",
    "        if idx0.ndim == 0:\n",
    "            idx0 = idx0.unsqueeze(0)\n",
    "\n",
    "        #### 複製weight ####\n",
    "        ################################################\n",
    "        #          請填空          #\n",
    "        ################################################\n",
    "        w = m0.weight.data.cpu().index_select(1, idx0)\n",
    "        m1.weight.data = w.to(m1.weight.device).clone()\n",
    "\n",
    "\n",
    "        #### 複製bias ####\n",
    "        m1.bias.data = m0.bias.data.clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0nUbcNtA_SA"
   },
   "source": [
    "## 測試函數\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Md44Lc-WBIaf"
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])),\n",
    "        batch_size=TEST_BATCH_SIZE, shuffle=True, **kwargs)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      for data, target in test_loader:\n",
    "          if CUDA:\n",
    "              data, target = data.cuda(), target.cuda()\n",
    "          data, target = Variable(data), Variable(target)\n",
    "          output = model(data)\n",
    "          pred = output.data.max(1, keepdim=True)[1]\n",
    "          correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "    return correct / float(len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFkMmFLo88mc"
   },
   "source": [
    "## 儲存模型並印出結果，以及剪枝後的test acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cuo3HXHt9Ar-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 122, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(122, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(122, 118, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(118, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 118, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(118, 123, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(123, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(123, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 102, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(102, 107, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(107, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(107, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(54, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(37, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 27, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(27, 31, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(31, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(23, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(62, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(3, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n",
      "Pruned model parameter count: 3,973,494\n",
      "Files already downloaded and verified\n",
      "\n",
      "Test set: Accuracy: 3215/10000 (32.2%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3215)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()}, PRUNE_PATH)\n",
    "\n",
    "print(newmodel)\n",
    "pruned_param_count = sum(p.numel() for p in newmodel.parameters())\n",
    "print(f\"Pruned model parameter count: {pruned_param_count:,}\")\n",
    "model = newmodel.cuda()\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ==========================================\n",
    "## PRUNE_PERCENT = 0.5 版本\n",
    "## =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRUNE_PERCENT_50 = 0.5  # 50% prune ratio\n",
    "PRUNE_PATH_50 = '/home/twccjq88/2025EAI_Project/EAI_Lab2/checkpoints/model_prune_50.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# 重新載入原始模型\n",
    "model_50 = ResNet50(num_classes=10)\n",
    "if CUDA:\n",
    "    model_50.cuda()\n",
    "\n",
    "if WEIGHT_PATH:\n",
    "    if os.path.isfile(WEIGHT_PATH):\n",
    "        checkpoint = torch.load(WEIGHT_PATH)\n",
    "        state_dict = checkpoint['state_dict']\n",
    "\n",
    "        cleaned_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            cleaned_key = k.replace('module.', '', 1) if k.startswith('module.') else k\n",
    "            cleaned_state_dict[cleaned_key] = v\n",
    "\n",
    "        model_50.load_state_dict(cleaned_state_dict)\n",
    "        print(f'LOADING CHECKPOINT FOR PRUNE_50: {WEIGHT_PATH}')\n",
    "    else:\n",
    "        print(\"NO CHECKPOINT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_50 = 0\n",
    "for m in model_50.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d) and m.weight is not None:\n",
    "        total_50 += m.weight.data.shape[0]\n",
    "\n",
    "bn_50 = torch.zeros(total_50)\n",
    "index_50 = 0\n",
    "for m in model_50.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d) and m.weight is not None:\n",
    "        size = m.weight.data.shape[0]\n",
    "        bn_50[index_50:(index_50+size)] = m.weight.data.abs().clone()\n",
    "        index_50 += size\n",
    "\n",
    "y_50, i_50 = torch.sort(bn_50)\n",
    "\n",
    "threshold_index_50 = min(total_50 - 1, int(total_50 * PRUNE_PERCENT_50))\n",
    "threshold_50 = y_50[threshold_index_50]\n",
    "print(f'Threshold for PRUNE_PERCENT=0.5: {threshold_50}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_50 = 0\n",
    "cfg_50 = []  #用來建立剪枝網路的CONFIG\n",
    "cfg_mask_50 = [] #用來幫助剪枝的遮罩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 第一步：建立初始 mask 和 cfg (PRUNE_PERCENT = 0.5) =====\n",
    "for k, m in enumerate(model_50.modules()):\n",
    "    if isinstance(m, nn.BatchNorm2d) and m.weight is not None:\n",
    "        weight_copy = m.weight.data.clone()\n",
    "        mask = weight_copy.abs().gt(threshold_50).float().to(weight_copy.device)\n",
    "        \n",
    "        if torch.sum(mask) == 0:\n",
    "            preserve = min(3, mask.numel())\n",
    "            _, idx = torch.topk(weight_copy.abs(), k=preserve, largest=True, sorted=False)\n",
    "            mask[idx] = 1.0\n",
    "        \n",
    "        m.weight.data.mul_(mask)\n",
    "        m.bias.data.mul_(mask)\n",
    "        pruned_50 = pruned_50 + mask.shape[0] - torch.sum(mask)\n",
    "        cfg_50.append(int(torch.sum(mask)))\n",
    "        cfg_mask_50.append(mask.detach().cpu().clone())\n",
    "\n",
    "\n",
    "# ===== 第二步：固定所有 BN3 到原始維度 =====\n",
    "original_output_dims = [256, 512, 1024, 2048]\n",
    "layers = [3, 4, 6, 3]\n",
    "cfg_idx = 1\n",
    "\n",
    "for layer_num, num_blocks in enumerate(layers):\n",
    "    target_dim = original_output_dims[layer_num]\n",
    "    \n",
    "    for b in range(num_blocks):\n",
    "        bn3_idx = cfg_idx + b * 3 + 2\n",
    "        cfg_50[bn3_idx] = target_dim\n",
    "        cfg_mask_50[bn3_idx] = torch.ones(target_dim)\n",
    "    \n",
    "    cfg_idx += num_blocks * 3\n",
    "\n",
    "\n",
    "# ===== 第三步：計算結果 =====\n",
    "print(\"=\"*70)\n",
    "print(f'cfg_50: {cfg_50}')\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 建立模型並計算參數\n",
    "newmodel_50 = ResNet50(num_classes=10, cfg=cfg_50)\n",
    "if CUDA:\n",
    "    newmodel_50.cuda()\n",
    "\n",
    "pruned_params_50 = sum(p.numel() for p in newmodel_50.parameters())\n",
    "original_params = 23_513_162\n",
    "\n",
    "print(f\"Pruned parameters (50%): {pruned_params_50:,} ({pruned_params_50/1e6:.2f}M)\")\n",
    "print(f\"Original parameters: {original_params:,} (23.51M)\")\n",
    "print(f\"Reduction: {(1 - pruned_params_50/original_params)*100:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel_50 = ResNet50(num_classes=10, cfg=cfg_50)\n",
    "newmodel_50.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查參數數量\n",
    "pruned_params_50 = sum(p.numel() for p in newmodel_50.parameters())\n",
    "original_params = 23_513_162\n",
    "\n",
    "print(f\"Pruned parameters (50%): {pruned_params_50:,} ({pruned_params_50/1e6:.2f}M)\")\n",
    "print(f\"Original parameters: {original_params:,} (23.51M)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_modules_50 = list(model_50.modules())\n",
    "new_modules_50 = list(newmodel_50.modules())\n",
    "\n",
    "layer_id_in_cfg_50 = 0\n",
    "start_mask_50 = torch.ones(3) #3為input channel(R,G,B)\n",
    "end_mask_50 = cfg_mask_50[layer_id_in_cfg_50]\n",
    "bn_count_50 = 0\n",
    "block_input_mask_50 = torch.ones(3)\n",
    "block_output_mask_50 = None\n",
    "\n",
    "for layer_id in range(len(old_modules_50)):\n",
    "    m0 = old_modules_50[layer_id]\n",
    "    m1 = new_modules_50[layer_id]\n",
    "\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        if m0.weight is None:\n",
    "            if block_output_mask_50 is not None:\n",
    "                idx = torch.nonzero(block_output_mask_50).squeeze().long().cpu()\n",
    "                if idx.ndim == 0:\n",
    "                    idx = idx.unsqueeze(0)\n",
    "                m1.running_mean = m0.running_mean.cpu().index_select(0, idx).to(m1.running_mean.device).clone()\n",
    "                m1.running_var = m0.running_var.cpu().index_select(0, idx).to(m1.running_var.device).clone()\n",
    "            continue\n",
    "\n",
    "        current_mask_50 = cfg_mask_50[layer_id_in_cfg_50]\n",
    "        \n",
    "        if bn_count_50 % 3 == 1:\n",
    "            if layer_id_in_cfg_50 == 0:\n",
    "                block_input_mask_50 = current_mask_50.clone()\n",
    "            else:\n",
    "                block_input_mask_50 = start_mask_50.clone()\n",
    "        \n",
    "        if bn_count_50 % 3 == 0 and bn_count_50 > 0:\n",
    "            block_output_mask_50 = current_mask_50.clone()\n",
    "        \n",
    "        bn_count_50 += 1\n",
    "        \n",
    "        idx = torch.nonzero(current_mask_50).squeeze().long()\n",
    "        if idx.ndim == 0:\n",
    "            idx = idx.unsqueeze(0)\n",
    "        idx = idx.cpu()\n",
    "\n",
    "        m1.weight.data = m0.weight.data.cpu().index_select(0, idx).to(m1.weight.device).clone()\n",
    "        m1.bias.data = m0.bias.data.cpu().index_select(0, idx).to(m1.bias.device).clone()\n",
    "        m1.running_mean = m0.running_mean.cpu().index_select(0, idx).to(m1.running_mean.device).clone()\n",
    "        m1.running_var = m0.running_var.cpu().index_select(0, idx).to(m1.running_var.device).clone()\n",
    "\n",
    "        layer_id_in_cfg_50 += 1\n",
    "        start_mask_50 = end_mask_50.clone()\n",
    "\n",
    "        if layer_id_in_cfg_50 < len(cfg_mask_50):\n",
    "            end_mask_50 = cfg_mask_50[layer_id_in_cfg_50]\n",
    "        else:\n",
    "            end_mask_50 = torch.ones_like(start_mask_50)\n",
    "\n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        if isinstance(old_modules_50[layer_id + 1], nn.BatchNorm2d) and old_modules_50[layer_id + 1].weight is not None:\n",
    "            idx0 = torch.nonzero(start_mask_50).squeeze().long().cpu()\n",
    "            idx1 = torch.nonzero(end_mask_50).squeeze().long().cpu()\n",
    "\n",
    "            if idx0.ndim == 0:\n",
    "                idx0 = idx0.unsqueeze(0)\n",
    "            if idx1.ndim == 0:\n",
    "                idx1 = idx1.unsqueeze(0)\n",
    "            w = m0.weight.data.cpu().index_select(1, idx0)\n",
    "            w = w.index_select(0, idx1)\n",
    "            m1.weight.data = w.to(m1.weight.device).clone()\n",
    "        else:\n",
    "            input_idx = torch.nonzero(block_input_mask_50).squeeze().long()\n",
    "            output_idx = torch.nonzero(block_output_mask_50).squeeze().long()\n",
    "            if input_idx.ndim == 0:\n",
    "                input_idx = input_idx.unsqueeze(0)\n",
    "            if output_idx.ndim == 0:\n",
    "                output_idx = output_idx.unsqueeze(0)\n",
    "            input_idx = input_idx.cpu()\n",
    "            output_idx = output_idx.cpu()\n",
    "            w = m0.weight.data.cpu().index_select(1, input_idx)\n",
    "            w = w.index_select(0, output_idx)\n",
    "            m1.weight.data = w.to(m1.weight.device).clone()\n",
    "\n",
    "    elif isinstance(m0, nn.Linear):\n",
    "        idx0 = torch.nonzero(start_mask_50).squeeze().long().cpu()\n",
    "        if idx0.ndim == 0:\n",
    "            idx0 = idx0.unsqueeze(0)\n",
    "        w = m0.weight.data.cpu().index_select(1, idx0)\n",
    "        m1.weight.data = w.to(m1.weight.device).clone()\n",
    "        m1.bias.data = m0.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'cfg': cfg_50, 'state_dict': newmodel_50.state_dict()}, PRUNE_PATH_50)\n",
    "\n",
    "print(newmodel_50)\n",
    "pruned_param_count_50 = sum(p.numel() for p in newmodel_50.parameters())\n",
    "print(f\"Pruned model parameter count (50%): {pruned_param_count_50:,}\")\n",
    "model_50_final = newmodel_50.cuda()\n",
    "test(model_50_final)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "EAI Lab1 (Python 3.9)",
   "language": "python",
   "name": "eai_lab1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
