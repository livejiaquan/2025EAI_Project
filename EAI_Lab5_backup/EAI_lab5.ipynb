{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOV/rmsswwtq7Dm7IE3hnwD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 2025 EAI Lab 5"],"metadata":{"id":"7KRm0_WztAPe"}},{"cell_type":"markdown","source":["## Topic 1 : From PyTorch To ONNX\n","\n","### Steps:\n","1.   Define Model Architecture\n","2.   Load Weight\n","3.   Export ONNX File\n","4.   Quantize To INT8\n","5.   Building Session\n","\n"],"metadata":{"id":"2e7m9tHTpR0H"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vt7LM45spK0Q"},"outputs":[],"source":["!pip install -U \\\n","    torch torchvision torchaudio \\\n","    onnx onnxscript onnxruntime onnxruntime-tools onnxruntime-gpu \\\n","    gradio"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# TODO\n","# Design Your ResNet18 Model\n","\n","class BasicBlock(nn.Module):\n","    def __init__():\n","\n","\n","    def forward(self, x):\n","\n","\n","class ResNet18(nn.Module):\n","    def __init__():\n","\n","\n","    def forward():\n"],"metadata":{"id":"MCKZlTEIqkOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","torch_model = ResNet18(ResBlock=BasicBlock, num_classes=10)\n","dummy_input = (torch.randn(1, 3, 32, 32),)\n","\n","def export_onnx(model, dummy, path):\n","  state = torch.load(path, map_location=torch.device(\"cpu\"))\n","\n","  # TODO : load state dict\n","\n","\n","  torch_model.eval()\n","\n","  # Todo : Export ONNX FILE\n","  torch.onnx.export(\n","\n","  )\n","  pass\n","\n","if __name__ == \"__main__\":\n","  # 提醒 : 記得先把 best_model.pth 上傳到 Content 資料夾\n","  export_onnx(model=torch_model, dummy=dummy_input, path=\"best_model.pth\")\n"],"metadata":{"id":"RUErZRINpUU5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, numpy as np\n","from PIL import Image\n","import onnxruntime as ort\n","from onnxruntime.quantization import CalibrationDataReader\n","\n","CIFAR10_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n","CIFAR10_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)\n","\n","def preprocess_32x32(pil_img: Image.Image) -> np.ndarray:\n","    arr = np.asarray(pil_img.convert(\"RGB\").resize((32, 32)), dtype=np.float32) / 255.0\n","    arr = (arr - CIFAR10_MEAN) / CIFAR10_STD\n","    return arr.transpose(2, 0, 1)[None, ...]  # (1,3,32,32)\n","\n","class CIFARLikeCalibReader(CalibrationDataReader):\n","    def __init__(self, image_dir: str = None, input_name: str = \"input\",\n","                 batch_size: int = 32, num_batches: int = 10):\n","        self.input_name  = input_name\n","        self.batch_size  = batch_size\n","        self.num_batches = num_batches\n","        self.paths = []\n","        if image_dir and os.path.isdir(image_dir):\n","            for f in os.listdir(image_dir):\n","                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n","                    self.paths.append(os.path.join(image_dir, f))\n","        self._mode_random = len(self.paths) == 0\n","        self._pos = 0\n","        self._emitted = 0\n","\n","    def get_next(self):\n","        if self._emitted >= self.num_batches:\n","            return None\n","        if self._mode_random:\n","            batch = np.random.randn(self.batch_size, 3, 32, 32).astype(np.float32)\n","        else:\n","            items = []\n","            for _ in range(self.batch_size):\n","                if self._pos >= len(self.paths):\n","                    break\n","                img = Image.open(self.paths[self._pos])\n","                self._pos += 1\n","                items.append(preprocess_32x32(img))\n","            if not items:\n","                return None\n","            batch = np.concatenate(items, axis=0).astype(np.float32)\n","        self._emitted += 1\n","        return {self.input_name: batch}\n","\n","    def rewind(self):\n","        self._pos = 0\n","        self._emitted = 0\n","\n","FP32_MODEL = \"image_classifier_model.onnx\"\n","INT8_MODEL = \"image_classifier_model_int8.onnx\"\n","\n","\n","_tmp = ort.InferenceSession(FP32_MODEL, providers=[\"CPUExecutionProvider\"])\n","INPUT_NAME = _tmp.get_inputs()[0].name\n","print(\"Calib will use input name:\", INPUT_NAME)\n"],"metadata":{"id":"PnBfgSxfpUzD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from onnxruntime.quantization import quantize_static, QuantType, CalibrationMethod\n","\n","\n","\n","reader = CIFARLikeCalibReader(\n","    image_dir=None,\n","    input_name=INPUT_NAME,\n","    batch_size=1,\n","    num_batches=50\n",")\n","\n","\n","def quantize_to_int8(fp32_path, int8_path, reader, method=\"MinMax\"):\n","    # Todo : quantize_static\n","    quantize_static(\n","\n","    )\n","    print(\"Saved INT8 model:\", INT8_MODEL)\n","\n","quantize_to_int8(FP32_MODEL, INT8_MODEL, reader)"],"metadata":{"id":"9_HL4D23phIN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","import numpy as np\n","import onnxruntime as ort\n","\n","def run(sess, x):\n","    return sess.run(None, {sess.get_inputs()[0].name: x})[0]\n","\n","x_demo = np.random.randn(1,3,32,32).astype(np.float32)\n","\n","# Todo : build session function\n","def build_session(model_path, providers):\n","  return\n","\n","\n","\n","sess_fp32 = build_session(model_path=FP32_MODEL, providers=[\"CPUExecutionProvider\"])\n","sess_int8 = build_session(model_path=INT8_MODEL, providers=[\"CPUExecutionProvider\"])\n","\n","y_fp32 = run(sess_fp32, x_demo)\n","y_int8 = run(sess_int8, x_demo)\n","\n","l2_rel = np.linalg.norm(y_fp32 - y_int8) / (np.linalg.norm(y_fp32) + 1e-12)\n","print(f\"[Check] relative L2 diff FP32 vs INT8: {l2_rel:.6f}\")\n","\n","def bench(sess, x, n=50):\n","    t0 = time.time()\n","    for _ in range(n):\n","        sess.run(None, {sess.get_inputs()[0].name: x})\n","    return (time.time() - t0) / n\n","\n","print(\"FP32 avg sec:\", bench(sess_fp32, x_demo))\n","print(\"INT8 avg sec:\", bench(sess_int8, x_demo))\n","\n","so = ort.SessionOptions()\n","so.enable_profiling = True\n","\n"],"metadata":{"id":"VYZIE2Rdpj3G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Topic 2 : Gradio\n"],"metadata":{"id":"OeFccLG1pehx"}},{"cell_type":"code","source":["! pip install gradio"],"metadata":{"id":"qFNo0K7gvJqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import onnxruntime as ort\n","import numpy as np\n","from PIL import Image\n","import gradio as gr\n","import time\n","\n","# ====== Config ======\n","MODEL_PATH_INT8 = \"image_classifier_model_int8.onnx\"   # INT8 ONNX Model\n","MODEL_PATH_FP32 = \"image_classifier_model.onnx\"     # FP32 ONNX Model\n","LABELS = ['plane','car','bird','cat','deer','dog','frog','horse','ship','truck']\n","\n","# CIFAR-10 Normalization Parameter\n","CIFAR10_MEAN = np.array([0.4914, 0.4822, 0.4465], dtype=np.float32)\n","CIFAR10_STD  = np.array([0.2470, 0.2435, 0.2616], dtype=np.float32)\n","\n","# ====== Utils ======\n","def softmax_np(x: np.ndarray) -> np.ndarray:\n","    x = x - np.max(x)\n","    ex = np.exp(x)\n","    return ex / np.sum(ex)\n","\n","# TODO : preprocess input image function\n","def preprocess(image: Image.Image) -> np.ndarray:\n","    \"\"\"輸入 PIL Image → (1,3,32,32) float32\"\"\"\n","    if not isinstance(image, Image.Image):\n","        raise ValueError(\"Plese Upload Image\")\n","\n","\n","    return arr\n","\n","# ====== ONNX Sessions ======\n","providers = ort.get_available_providers()\n","\n","sess_int8 = build_session(MODEL_PATH_INT8, providers=providers)\n","in_int8  = sess_int8.get_inputs()[0].name\n","out_int8 = sess_int8.get_outputs()[0].name\n","\n","\n","try:\n","    sess_fp32 = build_session(MODEL_PATH_FP32, providers=providers)\n","    in_fp32  = sess_fp32.get_inputs()[0].name\n","    out_fp32 = sess_fp32.get_outputs()[0].name\n","    _fp32_err = \"\"\n","except Exception as e:\n","    sess_fp32, in_fp32, out_fp32 = None, None, None\n","    _fp32_err = f\"[FP32 load failure] {type(e).__name__}: {e}\"\n","\n","# ====== Compare FP32 and INT8 ======\n","# TODO : Compare FP32 and INT8\n","def compare_fp32_int8(image: Image.Image):\n","    if image is None:\n","        return {}, {}, \"Please Upload Your Image。\"\n","    if sess_fp32 is None:\n","        return {}, {}, (_fp32_err or \"The FP32 model has not been provided, so a comparison cannot be made.\")\n","\n","    x = preprocess(image)\n","\n","    # Your progarm\n","\n","\n","    p_fp32 = softmax_np()\n","    p_int8 = softmax_np()\n","\n","    def top3_map(p):\n","        idx = np.argpartition(p, -3)[-3:]\n","        idx = idx[np.argsort(p[idx])[::-1]]\n","        return {LABELS[i]: float(p[i]) for i in idx}\n","\n","    top3_fp32 = top3_map(p_fp32)\n","    top3_int8 = top3_map(p_int8)\n","\n","    summary = (\n","        f\"FP32 inference time: {fp32_ms:.2f} ms\\n\"\n","        f\"INT8 inference time: {int8_ms:.2f} ms\\n\"\n","        f\"Speedup (FP32/INT8): {(fp32_ms / max(int8_ms, 1e-9)):.2f}×\"\n","    )\n","    return top3_fp32, top3_int8, summary\n","\n","# ====== Gradio UI ======\n","# TODO : Building GUI Interface\n","demo = gr.Interface(\n","    fn = compare_fp32_int8,\n","    inputs =\n","    outputs =\n","    title =\n","    description =\n",")\n","\n","if __name__ == \"__main__\":\n","  # TODO : building a public web\n","\n"],"metadata":{"id":"_vE9Tel_tI76"},"execution_count":null,"outputs":[]}]}